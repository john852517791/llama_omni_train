{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset,DataLoader,DistributedSampler\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_alpaca(Dataset):\n",
    "    def __init__(self,texts,prefix_prompt = \"\", suffix_prompt=\"\"):\n",
    "        \"\"\"self.list_IDs\t: list of strings (each string: utt key),\n",
    "           self.labels      : dictionary (key: utt key, value: label integer)\"\"\"\n",
    "        self.texts = texts\n",
    "        self.prefix_prompt = prefix_prompt\n",
    "        self.suffix_prompt = suffix_prompt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.prefix_prompt+self.texts[index]['instruction'] + self.texts[index]['input']+self.suffix_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [00:00, 108945.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"/data8/wangzhiyong/project/LLM/llama_omni/a_datasets/alpaca/subset/data\")\n",
    "suffix_prompt = \" Respond to the following input precisely and shortly in english. \"\n",
    "txtset = Dataset_alpaca(ds[\"train\"], suffix_prompt=suffix_prompt)\n",
    "alpaca_dl = DataLoader(txtset, batch_size=8, shuffle=True,drop_last = True,num_workers=0)\n",
    "print(len(txtset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Describe how machine learning can be used to automate mundane tasks. Respond to the following input precisely and shortly in english. ',\n",
       " 'Name 6 components of an artificial neural network Respond to the following input precisely and shortly in english. ',\n",
       " 'Create a dialog between two people who are discussing a scientific phenomenonHydropower Respond to the following input precisely and shortly in english. ',\n",
       " 'Explain the given concept in one sentence.Algorithmic complexity Respond to the following input precisely and shortly in english. ',\n",
       " 'Answer this math problem.12/8 Respond to the following input precisely and shortly in english. ',\n",
       " 'Name 3 countries that border France. Respond to the following input precisely and shortly in english. ',\n",
       " 'Create a list of three tips for public speaking. Respond to the following input precisely and shortly in english. ',\n",
       " 'Describe how quantum computers work. Respond to the following input precisely and shortly in english. ']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ind, a in enumerate(alpaca_dl):\n",
    "    if ind==0:\n",
    "        q = a\n",
    "        break\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_dir=\"/data8/wangzhiyong/project/LLM/llama_omni/b_pretrained_models/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_dir)\n",
    "model = LlamaForCausalLM.from_pretrained(llama_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "txttoken = tokenizer(q, return_tensors=\"pt\",padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,  75885,   1268,   5780,   6975,    649,    387,   1511,    311,\n",
       "          69711,  69782,   9256,     13,  40633,    311,    279,   2768,   1988,\n",
       "          24559,    323,  20193,    304,  30063,     13,    220, 128009, 128009,\n",
       "         128009],\n",
       "        [128000,    678,    220,     21,   6956,    315,    459,  21075,  30828,\n",
       "           4009,  40633,    311,    279,   2768,   1988,  24559,    323,  20193,\n",
       "            304,  30063,     13,    220, 128009, 128009, 128009, 128009, 128009,\n",
       "         128009],\n",
       "        [128000,   4110,    264,   7402,   1990,   1403,   1274,    889,    527,\n",
       "          25394,    264,  12624,  25885,  31916,   6861,   1223,  40633,    311,\n",
       "            279,   2768,   1988,  24559,    323,  20193,    304,  30063,     13,\n",
       "            220],\n",
       "        [128000,    849,  21435,    279,   2728,   7434,    304,    832,  11914,\n",
       "           9833,   7240,    292,  23965,  40633,    311,    279,   2768,   1988,\n",
       "          24559,    323,  20193,    304,  30063,     13,    220, 128009, 128009,\n",
       "         128009],\n",
       "        [128000,  16533,    420,   7033,   3575,     13,    717,     14,     23,\n",
       "          40633,    311,    279,   2768,   1988,  24559,    323,  20193,    304,\n",
       "          30063,     13,    220, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "         128009],\n",
       "        [128000,    678,    220,     18,   5961,    430,   3973,   9822,     13,\n",
       "          40633,    311,    279,   2768,   1988,  24559,    323,  20193,    304,\n",
       "          30063,     13,    220, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "         128009],\n",
       "        [128000,   4110,    264,   1160,    315,   2380,  10631,    369,    586,\n",
       "          12365,     13,  40633,    311,    279,   2768,   1988,  24559,    323,\n",
       "          20193,    304,  30063,     13,    220, 128009, 128009, 128009, 128009,\n",
       "         128009],\n",
       "        [128000,  75885,   1268,  31228,  19002,    990,     13,  40633,    311,\n",
       "            279,   2768,   1988,  24559,    323,  20193,    304,  30063,     13,\n",
       "            220, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "         128009]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txttoken.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_token = model.generate(**txttoken, max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,  75885,   1268,  ..., 128006, 128006, 128006],\n",
       "        [128000,    678,    220,  ..., 128006, 128006, 128006],\n",
       "        [128000,   4110,    264,  ...,    220,   1226,   1205],\n",
       "        ...,\n",
       "        [128000,    678,    220,  ..., 128006, 128006, 128006],\n",
       "        [128000,   4110,    264,  ..., 128006, 128006, 128006],\n",
       "        [128000,  75885,   1268,  ..., 128001, 128001, 128001]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "optxt = tokenizer.batch_decode([generated_token[i][len(txttoken.input_ids[i]):] for i in range(len(generated_token))], skip_special_tokens=True, clean_up_tokenization_spaces=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " ' I am a scientist, and I have been studying the effects of climate change on the world\\'s oceans.  I am particularly interested in the phenomenon of ocean acidification, which is caused by the absorption of CO2 from the atmosphere.  I have been studying the impact of this phenomenon on marine life, and I am concerned about the potential consequences for the future of our planet.\\n\\nA colleague:  \"I\\'m not sure I agree with your perspective on this.  Ocean acidification is not just a problem for marine life, it\\'s also a problem for human health.  We\\'re already seeing the effects of rising CO2 levels on coral reefs and other marine ecosystems.\"\\n\\nScientist:  \"I understand your point, but I still think that the impact of ocean acidification on marine life is more significant than the impact on human health.  For example, many marine species are already showing signs of adaptation to the changing CO2 levels, and some species are even evolving to thrive in these conditions.  However, I agree that the problem is still a significant one, and we need to take action to mitigate its effects.\"\\n\\nA colleague:  \"I see what you\\'re saying, but I think we need to consider the bigger picture.  Ocean acidification is just one of many factors that are contributing to the decline of marine ecosystems.  We need',\n",
       " \"assistant\\n\\nI'd be happy to explain the concept of algorithmic complexity in one sentence.\\n\\nAlgorithmic complexity refers to the amount of time or space an algorithm requires to complete a given task, usually measured in terms of its worst-case scenario, or the maximum amount of time or space an algorithm needs to run on a specific input.\\n\\nNow, please provide the input to be responded to in English.\",\n",
       " '.File a police report',\n",
       " '',\n",
       " '',\n",
       " ' restores']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optxt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
